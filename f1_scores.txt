baseline shallow mlp (no preprocessing such as cropping or standardisation):
Baseline MLP model: Sequential(
  (0): Linear(in_features=36608, out_features=4, bias=True)
)
Number of trainable parameters: 146436
Test: 
 Accuracy: 57.62%, Avg loss: 1.989750 

              precision    recall  f1-score   support

           0      0.895     0.095     0.172       179
           1      1.000     0.083     0.154        12
           2      0.577     0.923     0.710       640
           3      0.547     0.286     0.375       448

    accuracy                          0.576      1279
   macro avg      0.755     0.347     0.353      1279
weighted avg      0.615     0.576     0.512      1279

Confusion matrix, without normalization
[[ 17   0 109  53]
 [  0   1   7   4]
 [  0   0 591  49]
 [  2   0 318 128]] 



base shallow mlp (all models now use preprocessed data), get similar performance but with way fewer epochs and parameters
Baseline MLP model: Sequential(
  (0): Linear(in_features=27000, out_features=4, bias=True)
)
Number of trainable parameters: 108004
Best Validation Loss: 0.145112 

Test: 
 Accuracy: 56.45%, Avg loss: 3.816043 

              precision    recall  f1-score   support

           0      1.000     0.061     0.116       179
           1      1.000     0.083     0.154        12
           2      0.592     0.822     0.688       640
           3      0.485     0.411     0.445       448

    accuracy                          0.565      1279
   macro avg      0.769     0.344     0.351      1279
weighted avg      0.616     0.565     0.518      1279

Confusion matrix, without normalization
[[ 11   0  92  76]
 [  0   1   6   5]
 [  0   0 526 114]
 [  0   0 264 184]]





 base deep mlp
 Baseline MLP model: Sequential(
  (0): Linear(in_features=27000, out_features=1000, bias=True)
  (1): ReLU()
  (2): Linear(in_features=1000, out_features=1000, bias=True)
  (3): ReLU()
  (4): Linear(in_features=1000, out_features=4, bias=True)
)
Number of trainable parameters: 28006004
Test: 
 Accuracy: 61.69%, Avg loss: 2.113830 

              precision    recall  f1-score   support

           0      0.882     0.251     0.391       179
           1      1.000     0.167     0.286        12
           2      0.722     0.641     0.679       640
           3      0.505     0.741     0.600       448

    accuracy                          0.617      1279
   macro avg      0.777     0.450     0.489      1279
weighted avg      0.671     0.617     0.607      1279

Confusion matrix, without normalization
[[ 45   0  43  91]
 [  0   2   0  10]
 [  5   0 410 225]
 [  1   0 115 332]]

 
CNN model:
Best Validation Loss: 0.033501 

Test: 
 Accuracy: 69.74%, Avg loss: 1.869457 

              precision    recall  f1-score   support

           0      0.802     0.430     0.560       179
           1      1.000     0.250     0.400        12
           2      0.752     0.778     0.765       640
           3      0.606     0.701     0.650       448

    accuracy                          0.697      1279
   macro avg      0.790     0.540     0.594      1279
weighted avg      0.710     0.697     0.693      1279

Confusion matrix, without normalization
[[ 77   0  33  69]
 [  0   3   5   4]
 [ 11   0 498 131]
 [  8   0 126 314]] 




ResNet Model:
Best Validation Loss: 0.035592 

Test: 
 Accuracy: 73.10%, Avg loss: 1.456225 

              precision    recall  f1-score   support

           0      0.938     0.419     0.579       179
           1      1.000     0.333     0.500        12
           2      0.739     0.850     0.791       640
           3      0.680     0.696     0.688       448

    accuracy                          0.731      1279
   macro avg      0.839     0.575     0.639      1279
weighted avg      0.749     0.731     0.722      1279

Confusion matrix, without normalization
[[ 75   0  56  48]
 [  0   4   3   5]
 [  2   0 544  94]
 [  3   0 133 312]]



 SVM using ResNet as feature extractor:
 Test: 
 Accuracy: 72.95%, Avg loss: 0.737267 

              precision    recall  f1-score   support

           0      0.900     0.453     0.602       179
           1      1.000     0.167     0.286        12
           2      0.751     0.841     0.794       640
           3      0.662     0.696     0.679       448

    accuracy                          0.729      1279
   macro avg      0.828     0.539     0.590      1279
weighted avg      0.743     0.729     0.722      1279

Confusion matrix, without normalization
[[ 81   0  46  52]
 [  0   2   3   7]
 [  2   0 538 100]
 [  7   0 129 312]]









